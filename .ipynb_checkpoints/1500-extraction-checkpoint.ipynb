{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(file_names):\n",
    "    \"\"\" Get all the sections within a particular group.\n",
    "    \n",
    "    Args:\n",
    "        file_names (list): has the names of all the csv files (that look like term test *.csv) from which all section names will\n",
    "                       be taken out\n",
    "    \n",
    "    Returns:\n",
    "        sections (list): list of all the sections within the particular gorup.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_names[0])\n",
    "    sections = df['Section'].unique()\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_cols(file_names):\n",
    "    \"\"\" Gets rid of all the unecessary columns that one does not want in the final gradebook\n",
    "    \n",
    "    Args:\n",
    "        file_names(list): has the names of all the csv files (that look like term test *.csv) from which all section names will\n",
    "                          be taken out\n",
    "                       \n",
    "    Returns:\n",
    "        list_of_dfs (list): a list of dataframes with all the unwanted columns removed from each of the dataframes\n",
    "    \n",
    "    \"\"\"\n",
    "    list_of_dfs = []\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name)\n",
    "        remove_cols = ['Crowdmark ID', 'Score URL', 'MC-total', 'Total', 'Penalty','Custom Penalty', 'Submitted At', 'State']\n",
    "        # get the question columns\n",
    "        q_cols = [col for col in df.columns if col[0] == 'Q']\n",
    "        # include the question columns in the remove_cols\n",
    "        remove_cols.extend(q_cols)\n",
    "        # remove the unwanted columns\n",
    "        df.drop(remove_cols, axis = 1, inplace=True)\n",
    "        # append the dataframe containing the required columns to the list of dataframes\n",
    "        list_of_dfs.append(df)\n",
    "    return list_of_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_only_results(list_of_dfs, section):\n",
    "    \"\"\" Gets the list of dataframes for a particular section\n",
    "    \n",
    "    Args:\n",
    "        list_of_dfs (list): the list of dataframes (returned by remove_unwanted_cols(file_names) function)\n",
    "        section (str): section name for which you want the dataframes\n",
    "    \n",
    "    Returns:\n",
    "        clean_dfs (list): list of dataframes wherein each dataframe has results corresponding only to the section provided \n",
    "                          as an arugment to the function\n",
    "    \n",
    "    \"\"\"\n",
    "    clean_dfs = []\n",
    "    for index, df in enumerate(list_of_dfs):\n",
    "        clean_df = df[df['Section'] == section]\n",
    "        num_entries = clean_df.shape[0]\n",
    "        \n",
    "        indices = [i for i in range(1,num_entries+1)]\n",
    "        clean_df.index = indices\n",
    "        \n",
    "        # rename columns\n",
    "        clean_df.rename(columns = {'Student ID Number':'Student ID', 'Total After Penalty':f'Term Test {index +1}'}, inplace = True)\n",
    "        \n",
    "        clean_dfs.append(clean_df)\n",
    "    return clean_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dfs(clean_dfs):\n",
    "    sorted_dfs = []\n",
    "    for clean_df in clean_dfs:\n",
    "        sorted_df = clean_df.sort_values('Name')\n",
    "        sorted_df.set_index(['Email', 'Name', 'Student ID', 'Section'], inplace = True)\n",
    "        sorted_dfs.append(sorted_df)\n",
    "    return sorted_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_dataframe(sorted_dfs):\n",
    "    \"\"\" Returns a single dataframe that contains results of all the term tests (merged from all the dataframes in clean_dfs)\n",
    "    \n",
    "    Args:\n",
    "        sorted_dfs (list): the list of sorted dataframes returned by sort_dfs(clean_dfs) function\n",
    "    \n",
    "    Returns:\n",
    "        final_df (dataframe): the dataframe consists of results from all the term tests for each of teh student\n",
    "    \n",
    "    \"\"\"\n",
    "    final_df = pd.concat(sorted_dfs, axis=1, join='inner')\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(final_df):\n",
    "    \"\"\" Fill the entries corresponding to the missed tests (which are represented as NaN values in the dataframe)\n",
    "    \n",
    "    Args:\n",
    "        final_df (dataframe): returned by the get_final_dataframe(clean_dfs) function\n",
    "        \n",
    "    Returns:\n",
    "        final_df (dataframe): all the NaN values filled with \"M\" (for missed tests)\n",
    "    \"\"\"\n",
    "    for col in final_df.columns:\n",
    "        final_df[col].fillna(\"M\", inplace = True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_excel(file_names, section):\n",
    "    \"\"\" Generates the xlsx files by calling the functions that are created above\n",
    "    \n",
    "    Args:\n",
    "        file_names(list): has the names of all the csv files (that look like term test *.csv) from which all section names will\n",
    "                          be taken out\n",
    "        section (str): section name for which you want the dataframes and then the final excel files    \n",
    "    \"\"\"\n",
    "    xls_file = f'1500 {section}.xlsx'\n",
    "    list_of_dfs = remove_unwanted_cols(file_names)\n",
    "    clean_dfs = section_only_results(list_of_dfs, section)\n",
    "    sorted_dfs = sort_dfs(clean_dfs)\n",
    "    final_df = get_final_dataframe(sorted_dfs)\n",
    "    final_df = fill_nans(final_df)\n",
    "    final_df.to_excel(xls_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    The caller function that calls all the above functions. Also asks the user for number of files in the group to be analyzed. \n",
    "    \"\"\"\n",
    "    num_files = input(\"Enter the number of csv files in the group: \")\n",
    "    file_names = [f\"term test {str(i)}.csv\" for i in range(1,int(num_files)+1)]\n",
    "    sections = get_sections(file_names)\n",
    "    for section in sections:\n",
    "        generate_excel(file_names, section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of csv files in the group: 9\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-gpu",
   "language": "python",
   "name": "py37-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
